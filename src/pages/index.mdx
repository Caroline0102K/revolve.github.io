---
layout: ../layouts/Layout.astro
title: Jailbreaking Large Language Models Against Moderation Guardrails via Cipher Characters
description: Simple project page template for your research paper, built with Astro and Tailwind CSS
favicon: favicon.svg
thumbnail: screenshot.png
---
import WarningWithCheckbox from '../components/Warnings.astro';
import Application from '../components/Application.astro';
import Layout from "../layouts/Layout.astro";
import GetInvolved from "../components/involved.astro";
import Header from "../components/Header.astro";
import Video from "../components/Video.astro";
import HighlightedSection from "../components/HighlightedSection.astro";
import SmallCaps from "../components/SmallCaps.astro";
import Figure from "../components/Figure.astro";
import Image from "../components/Image.astro";
import TwoColumns from "../components/TwoColumns.astro";
import YouTubeVideo from "../components/YouTubeVideo.astro";
import LaTeX from "../components/LaTeX.astro";
import poster from "../assets/poster.PNG";
import outside from "../assets/outside.mp4";
import method_comparison from "../assets/method_comparison.png";
import Splat from "../components/Splat.tsx"

import CodeBlock from "../components/CodeBlock.astro";
export const components = {pre: CodeBlock}

<Header
  title={frontmatter.title}
  authors={[
    {
      name: "Peiyan Zhang",
      url: "https://peiyance.github.io/",
      institution: "Hong Kong University of Science and Technology",
    },
    {
      name: "Haibo Jin",
      url: "https://haibojin001.github.io/",
      institution: "University of Illinois at Urbana-Champaign",
    },
    {
      name: "Leyang Hu",
      institution: "Brown University",
    },
    {
      name: "Xinnuo Li",
      institution: "University of Michigan - Ann Arbor",
    },
    {
      name: "Liying Kang",
      url: "https://github.com/jomenke",
      institution: "Hong Kong Polytechnic University",
    },
    {
      name: "Man Luo",
      url: "https://github.com/jomenke",
      institution: "Intel Lab",
    },
    {
      name: "Yangqiu Song",
      url: "https://github.com/jomenke",
      institution: "Hong Kong University of Science and Technology",
    },
    {
      name: "Haohan Wang",
      url: "https://haohanwang.github.io/",
      institution: "University of Illinois at Urbana-Champaign",
      notes: ["†"],
    },
  ]}
  notes={[
    {
      symbol: "†",
      text: "Corresponding Author",
    },
  ]}
  links={[
    {
      name: "Paper",
      url: "https://arxiv.org/pdf/2412.03092",
      icon: "fa-solid:file-pdf",
    },
    {
      name: "Code",
      url: "https://github.com/Peiyance/REVOLVE",
      icon: "mdi:github",
    },
    {
      name: "arXiv",
      url: "https://arxiv.org/abs/2412.03092",
      icon: "academicons:arxiv",
    },
  ]}
  />

 {/*<Video source={outside} />*/}

<HighlightedSection>

## About

Recent advancements in large language models (LLMs) have significantly enhanced the ability of LLM-based systems to perform complex tasks through natural language processing and tool interaction. However, optimizing these LLM-based systems for specific tasks remains challenging, often requiring manual interventions like prompt engineering and hyperparameter tuning. Existing automatic optimization methods, such as textual feedback-based techniques (e.g., TextGrad), tend to focus on immediate feedback, analogous to using immediate derivatives in traditional numerical gradient descent. However, relying solely on such feedback can be limited when the adjustments made in response to this feedback are either too small or fluctuate irregularly, potentially slowing down or even stalling the optimization process.  To overcome these challenges, more adaptive methods are needed, especially in situations where the system’s response is evolving slowly or unpredictably. In this paper, we introduce **REVOLVE**, an optimization method that tracks how **R**esponses **EVOLVE** across iterations in LLM systems. By focusing on the evolution of responses over time, REVOLVE enables more stable and effective optimization by making thoughtful, progressive adjustments at each step. We evaluate the effectiveness of REVOLVE across three tasks: prompt optimization, solution optimization, and code optimization. Experimental results demonstrate that REVOLVE outperforms competitive baselines, achieving a **7.8%** improvement in prompt optimization, a **20.72%** gain in solution refinement, and a **29.17%** increase in code optimization. Additionally, REVOLVE converges in fewer iterations, resulting in significant computational savings. These advantages highlight its adaptability and efficiency, positioning REVOLVE as a valuable tool for optimizing LLM-based systems and accelerating the development of next-generation AI technologies.

</HighlightedSection>



## Motivation
<TwoColumns>
<Figure
    caption=""
  >
    <Image source={method_comparison} altText="The illustrative comparison between REVOLVE and first-order optimization methods." />
</Figure>

- REVOLVE is an optimization framework that enhances the stability and efficiency of AI system optimization by tracking the evolution of model responses across iterations. Building on textual feedback from LLMs, Revolve simulates higher-order optimization effects, ensuring that adjustments are guided not only by immediate feedback but also by the model’s performance trajectory, leading to faster and more stable optimization without relying on traditional derivative-based methods.
- REVOLVE offers an intuitive API, built upon the foundation of [TextGrad] (https://github.com/zou-group/textgrad), that allows users to define custom optimization tasks and loss functions. This makes it an adaptable and effective tool for optimizing LLM-based systems across a range of applications, including prompt optimization, solution refinement, and code optimization.
</TwoColumns>

## Examples
  <Application />

## Paper Showcase

The presentation video on the left explains the problem addressed, our methodology, and key outcomes, helping viewers understand the broader impact of our work. On the right, the poster offers a visual summary of major findings and innovations, designed to capture the core essence of our research at a glance.

<TwoColumns>
  <Figure slot="left" caption="Watch our paper presentation video.">
    <YouTubeVideo videoId="E2P6XKi6HMs" />
  </Figure>
  <Figure slot="right" caption="Here is the poster for our paper.">
    {/*<Splat client:idle />*/}
   <Image source={poster} altText="Diagram of the transformer deep learning architecture." />
  </Figure>
</TwoColumns>


## Get Involved
<GetInvolved />

## BibTeX citation

```bibtex
@article{jin2024jailbreaking,
  title={Jailbreaking Large Language Models Against Moderation Guardrails via Cipher Characters},
  author={Jin, Haibo and Zhou, Andy and Menke, Joe D and Wang, Haohan},
  journal={arXiv preprint arXiv:2405.20413},
  year={2024}
}
```
